{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (944 users x 1683 items x 100000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "### approach first made popular by the Netflix prize contest: matrix factorization. ###\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')\n",
    "print(dataset)\n",
    "\n",
    "# The dataset object is an instance of an Interactions class, a fairly light-weight wrapper that\n",
    "# Spotlight users to hold the arrays that contain information about an interactions dataset (such as user\n",
    "# and item ids, ratings, and timestamps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taken from https://maciejkula.github.io/spotlight/factorization/explicit.html#spotlight.factorization.explicit.ExplicitFactorizationModel\n",
    "\n",
    "Parameters:\t\n",
    "- loss (string, optional) – One of ‘regression’, ‘poisson’, ‘logistic’ corresponding to losses from spotlight.losses.\n",
    "- embedding_dim (int, optional) – Number of embedding dimensions to use for users and items.\n",
    "-n_iter (int, optional) – Number of iterations to run.\n",
    "\n",
    "-batch_size (int, optional) – Minibatch size.\n",
    "\n",
    "-l2 (float, optional) – L2 loss penalty.\n",
    "\n",
    "-learning_rate (float, optional) – Initial learning rate.\n",
    "\n",
    "-optimizer_func (function, optional) – Function that takes in module parameters as the first argument and returns an instance of a PyTorch optimizer. Overrides l2 and learning rate if supplied. If no optimizer supplied, then use ADAM by default.\n",
    "\n",
    "-use_cuda (boolean, optional) – Run the model on a GPU.\n",
    "\n",
    "-representation (a representation module, optional) – If supplied, will override default settings and be used as the main network module in the model. Intended to be used as an escape hatch when you want to reuse the model’s training functions but want full freedom to specify your network topology.\n",
    "\n",
    "-sparse (boolean, optional) – Use sparse gradients for embedding layers.\n",
    "\n",
    "-random_state (instance of numpy.random.RandomState, optional) – Random state to use when fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "\n",
    "model = ExplicitFactorizationModel(loss='regression',\n",
    "                                   embedding_dim=128,  # latent dimensionality\n",
    "                                   n_iter=10,  # number of epochs of training\n",
    "                                   batch_size=1024,  # minibatch size\n",
    "                                   l2=1e-9,  # strength of L2 regularization\n",
    "                                   learning_rate=1e-3,\n",
    "                                   use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model\n",
    "We can feed our dataset to the ExplicitFactorizationModel class - and sklearn-like object that allows us to train and evaluate the explicit factorization models.\n",
    "\n",
    "Internally, the model uses the BilinearNet class to represents users and items. It's composed of a 4 embedding layers:\n",
    "\n",
    "a (num_users x latent_dim) embedding layer to represent users,\n",
    "\n",
    "a (num_items x latent_dim) embedding layer to represent items,\n",
    "\n",
    "a (num_users x 1) embedding layer to represent user biases, and\n",
    "\n",
    "a (num_items x 1) embedding layer to represent item biases.\n",
    "\n",
    "Together, these give us the predictions. Their accuracy is evaluated using one of the Spotlight losses. In this case, we'll use the regression loss, which is simply the squared difference between the true and the predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into \n",
      " <Interactions dataset (944 users x 1683 items x 80000 interactions)> and \n",
      " <Interactions dataset (944 users x 1683 items x 20000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test set\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(42))\n",
    "print('Split into \\n {} and \\n {}'.format(train, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 13.129207152354565\n",
      "Epoch 1: loss 7.510111075413378\n",
      "Epoch 2: loss 1.791443021991585\n",
      "Epoch 3: loss 1.0732096886333031\n",
      "Epoch 4: loss 0.9460989712159845\n",
      "Epoch 5: loss 0.8974253467366665\n",
      "Epoch 6: loss 0.8725832889351663\n",
      "Epoch 7: loss 0.8591318568096885\n",
      "Epoch 8: loss 0.8486642867703981\n",
      "Epoch 9: loss 0.8395742698560787\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 0.902, test RMSE 0.945\n"
     ]
    }
   ],
   "source": [
    "# Model valuation using Root Mean Square Error\n",
    "from spotlight.evaluation import rmse_score\n",
    "\n",
    "train_rmse = rmse_score(model, train)\n",
    "test_rmse = rmse_score(model, test)\n",
    "\n",
    "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
